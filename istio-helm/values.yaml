istio-base:
  enabled: true
  _internal_defaults_do_not_set:
    global:
      imagePullSecrets:
        - regcred

istiod:
  enabled: true
  _internal_defaults_do_not_set:
    autoscaleEnabled: false
    replicaCount: 1

    # Can be a full hub/image:tag
    image: pilot
    traceSampling: 1.0

    # Resources for a small pilot install
    resources:
      requests:
        cpu: 500m
        memory: 1024Mi

    # Set to `type: RuntimeDefault` to use the default profile if available.
    seccompProfile:
      type: RuntimeDefault

    # Additional container arguments
    extraContainerArgs: []

    env: {}

    # Inject initContainers into the istiod pod
    initContainers: []

    ## Mesh config settings

    # Install the mesh config map, generated from values.yaml.
    # If false, pilot wil use default values (by default) or user-supplied values.
    configMap: true

    telemetry:
      enabled: true
      v2:
        # For Null VM case now.
        # This also enables metadata exchange.
        enabled: true
        # Indicate if prometheus stats filter is enabled or not
        prometheus:
          enabled: true
        # stackdriver filter settings.
        stackdriver:
          enabled: false

    # meshConfig defines runtime configuration of components, including Istiod and istio-agent behavior
    # See https://istio.io/docs/reference/config/istio.mesh.v1alpha1/ for all available options
    meshConfig:
      enablePrometheusMerge: true

    experimental:
      stableValidationPolicy: false

    global:
      # Used to locate istiod.
      istioNamespace: istio-system

      # A minimal set of requested resources to applied to all deployments so that
      # Horizontal Pod Autoscaler will be able to function (if set).
      # Each component can overwrite these default values by adding its own resources
      # block in the relevant section below and setting the desired resources values.
      defaultResources:
        requests:
          cpu: 10m
          memory: 128Mi
        limits:
          cpu: 100m
          memory: 128Mi

      # Default hub for Istio images.
      # Releases are published to docker hub under 'istio' project.
      # Dev builds from prow are on gcr.io
      hub: docker.io/istio
      # Default tag for Istio images.
      tag: 1.24.3
      # Variant of the image to use.
      # Currently supported are: [debug, distroless]
      variant: ""

      # Specify image pull policy if default behavior isn't desired.
      # Default behavior: latest images will be Always else IfNotPresent.
      imagePullPolicy: ""

      imagePullSecrets:
        - regcred

      # Enabled by default in master for maximising testing.
      istiod:
        enableAnalysis: false

      # To output all istio components logs in json format by adding --log_as_json argument to each container argument
      logAsJson: false

      # Comma-separated minimum per-scope logging level of messages to output, in the form of <scope>:<level>,<scope>:<level>
      # The control plane has different scopes depending on component, but can configure default log level across all components
      # If empty, default scope and level will be used as configured in code
      logging:
        level: "default:info"

      omitSidecarInjectorConfigMap: false

      proxy:
        image: proxyv2

        # This controls the 'policy' in the sidecar injector.
        autoInject: enabled

        # Resources for the sidecar.
        resources:
          requests:
            cpu: 40m
            memory: 64Mi
          limits:
            cpu: 80m
            memory: 128Mi

        # Default port for Pilot agent health checks. A value of 0 will disable health checking.
        statusPort: 15020

        # Specify which tracer to use. One of: zipkin, lightstep, datadog, stackdriver, none.
        # If using stackdriver tracer outside GCP, set env GOOGLE_APPLICATION_CREDENTIALS to the GCP credential file.
        tracer: "none"

      ##############################################################################################
      # The following values are found in other charts. To effectively modify these values, make   #
      # make sure they are consistent across your Istio helm charts                                #
      ##############################################################################################

    base:
      # For istioctl usage to disable istio config crds in base
      enableIstioConfigCRDs: true

kube-netlag:
  enabled: true
  imagePullSecrets:
    - name: "regcred"
  nameOverride: "kube-netlag"
  namespaceOverride: kube-netlag
  prometheusConfig:
    create: true
    namespace: "istio-system"

prometheus:
  enabled: true
  imagePullSecrets:
    - name: "regcred"

  configmapReload:
    enabled: true
    # prometheus:
    #   extraConfigmapMounts:
    #     - name: kube-netlag
    #       mountPath: /etc/config/kube-netlag
    #       subPath: "kube-netlag.yaml"
    #       configMap: kube-netlag
    #       readOnly: true

  prometheus:
    enabled: true
    name: configmap-reload
    resources:
      limits:
        cpu: "200m"
        memory: "100Mi"
      requests:
        cpu: "100m"
        memory: "50Mi"

  server:
    name: server
    fullnameOverride: "prometheus"
    ## namespaces to monitor (instead of monitoring all - clusterwide). Needed if you want to run without Cluster-admin privileges.
    image:
      repository: quay.io/prometheus/prometheus
      # if not set appVersion field from Chart.yaml is used
      tag: ""
      # When digest is set to a non-empty value, images will be pulled by digest (regardless of tag value).
      digest: ""
      pullPolicy: IfNotPresent

    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 1m
    persistentVolume:
      enabled: true
      accessModes:
        - ReadWriteOnce
      mountPath: /data
      size: 8Gi
    replicaCount: 1
    ## Prometheus data retention period (default if not specified is 15 days)
    ##
    retention: "1d"
    service:
      ## If false, no Service will be created for the Prometheus server
      ##
      enabled: true
      servicePort: 9090
      type: ClusterIP

    # extraConfigmapMounts:
    #     - name: kube-netlag
    #       mountPath: /etc/config/kube-netlag
    #       configMap: kube-netlag
    #       readOnly: true
    ## Prometheus server ConfigMap entries for scrape_config_files
    ## (allows scrape configs defined in additional files)
    ##
  # scrapeConfigFiles:
  #   - /etc/config/kube-netlag/kube-netlag.yaml
  extraScrapeConfigs: |-
    - job_name: "kube-state-metrics"
      metrics_path: /metrics
      kubernetes_sd_configs:
        - role: endpoints
      relabel_configs:
        - source_labels:
            [
              __meta_kubernetes_namespace,
              __meta_kubernetes_service_name,
              __meta_kubernetes_endpoint_port_name,
            ]
          action: keep
          regex: kube-system;kube-state-metrics;http-metrics
    - job_name: "node-exporter"
      kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
              - istio-system
      relabel_configs:
        - source_labels: [__meta_kubernetes_service_name]
          action: keep
          regex: node-exporter
    - job_name: envoy-stats
      metrics_path: /stats/prometheus
      kubernetes_sd_configs:
        - role: pod
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_container_port_name]
          action: keep
          regex: ".*-envoy-prom"
    - job_name: "istiod"
      kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
              - istio-system
      relabel_configs:
        - source_labels:
            [
              __meta_kubernetes_service_name,
              __meta_kubernetes_endpoint_port_name,
            ]
          action: keep
          regex: istiod;http-monitoring
    - job_name: "kube-netlag-daemon"
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
              - kube-netlag
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
          action: keep
          regex: kube-netlag
        - source_labels: [__meta_kubernetes_namespace]
          action: keep
          regex: kube-netlag
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          regex: (.+)
          target_label: __metrics_path__
          replacement: /metrics
        - source_labels:
            [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: (.+):(?:\d+);(9090)
          replacement: $1:$2
          target_label: __address__
        - source_labels: [__meta_kubernetes_pod_node_name]
          target_label: node
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod

  ## kube-state-metrics sub-chart configurable values
  ## Please see https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics
  ##
  kube-state-metrics:
    ## If false, kube-state-metrics sub-chart will not be installed
    ##
    enabled: true

  ## prometheus-node-exporter sub-chart configurable values
  ## Please see https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus-node-exporter
  ##
  prometheus-node-exporter:
    ## If false, node-exporter will not be installed
    ##
    enabled: true


kiali:
  enabled: true
  nameOverride: "kiali"
  fullnameOverride: ""

  image: # see: https://quay.io/repository/kiali/kiali-operator?tab=tags
    repo: quay.io/kiali/kiali-operator # quay.io/kiali/kiali-operator
    tag: v2.6.0 # version string like v1.39.0 or a digest hash
    digest: "" # use "sha256" if tag is a sha256 hash (do NOT prefix this value with a "@")
    pullPolicy: Always
    pullSecrets: []

  # Deployment options for the operator pod.
  env: []
  resources:
    requests:
      cpu: "10m"
      memory: "64Mi"

  # metrics.enabled: set to true if you want Prometheus to collect metrics from the operator
  metrics:
    enabled: true

  # Defines where the operator will look for Kial CR resources. "" means "all namespaces".
  watchNamespace: ""

  # For what a Kiali CR spec can look like, see: https://kiali.io/docs/configuration/kialis.kiali.io/
  cr:
    create: true
    name: kiali
    # If you elect to create a Kiali CR (--set cr.create=true)
    # and the operator is watching all namespaces (--set watchNamespace="")
    # then this is the namespace where the CR will be created (the default will be the operator namespace).
    namespace: "istio-system"

    # Annotations to place in the Kiali CR metadata.
    annotations: {}
      
    spec:
      deployment:
        cluster_wide_access: true
      auth:
        strategy: anonymous